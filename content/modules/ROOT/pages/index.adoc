= Welcome to the Low-Latency Performance Workshop!

[%hardbreaks]
== Introduction

Welcome to the comprehensive OpenShift Low-Latency Performance Workshop! This hands-on workshop will guide you through implementing high-performance, low-latency workloads on OpenShift 4.20 using enterprise-grade tuning techniques.

This workshop demonstrates real-world scenarios where microsecond-level latency matters, including financial trading systems, real-time gaming, IoT edge computing, and high-frequency data processing applications.

== Who Will Benefit Most from Attending?

*Platform Engineers & SREs* -- Learn advanced OpenShift performance tuning, CPU isolation, real-time kernel configuration, and automated cluster management at scale.

*Application Architects* -- Understand how to design containerized applications for ultra-low latency requirements while leveraging performance optimization techniques.

*DevOps Engineers* -- Master performance tuning techniques for consistent performance profile deployment across development, staging, and production environments.

== What Content Is Covered?

These are the *key modules* that will be covered:

* _Module 1: Low-Latency Fundamentals_: Understanding latency requirements, OpenShift performance features, and workshop architecture overview.

* _Module 2: Environment Setup and Verification_: Verifying your pre-configured SNO cluster and understanding the installed operators.

* _Module 3: Baseline Performance Testing_: Using kube-burner to establish performance baselines and measure pod creation latency metrics.

* _Module 4: Core Performance Tuning_: Implementing Performance Profiles for CPU isolation, HugePages configuration, and real-time kernel enablement.

* _Module 5: Low-Latency Virtualization_: Optimizing OpenShift Virtualization for low-latency workloads with SR-IOV networking and VM performance tuning.

* _Module 6: Monitoring & Validation_: Advanced performance monitoring, validation tools, and best practices for maintaining low-latency environments.

* _Module 7: GPU Workloads (Optional)_: Configuring and optimizing GPU workloads on OpenShift using the NVIDIA GPU Operator.

== What is Low-Latency Performance?

* **Microsecond Response Times**: Applications requiring sub-millisecond response times for critical operations
* **CPU Isolation**: Dedicated CPU cores for time-sensitive workloads without interference from system processes  
* **Real-time Kernels**: Deterministic scheduling and reduced jitter for predictable performance
* **Hardware Acceleration**: Direct hardware access via SR-IOV for network-intensive applications
* **Memory Optimization**: HugePages and NUMA-aware allocation for reduced memory management overhead

=== Workshop Technologies

This workshop leverages several OpenShift 4.20 enterprise features:

* **Node Tuning Operator**: Built-in operator for automated node tuning and Performance Profiles
* **SR-IOV Network Operator**: High-performance networking with direct hardware access
* **OpenShift Virtualization**: KubeVirt-based virtual machines with performance optimization
* **Performance Profiles**: Declarative CPU isolation, HugePages, and real-time kernel configuration

== Why Choose OpenShift for Low-Latency Workloads?

**Enterprise-Grade Performance:**
OpenShift provides certified, supportable low-latency capabilities backed by Red Hat engineering and extensive performance testing across diverse hardware platforms.

**Automated Lifecycle Management:**
OpenShift provides declarative Performance Profiles that enable consistent performance tuning across nodes without manual intervention.

**Production-Ready Integration:**
Native integration between performance tuning, container orchestration, and enterprise security provides a complete platform for mission-critical low-latency applications.

== Next Steps

Ready to start? Begin with Module 1 to understand the fundamentals, then progress through hands-on exercises that build upon each other.

**Learning Path:** +
1. **Start Here**: xref:module-01-low-latency-intro.adoc[Module 1 - Low-Latency Fundamentals] +
2. **Environment Setup**: xref:module-02-environment-setup.adoc[Module 2 - Environment Setup and Verification] +
3. **Performance Baseline**: xref:module-03-baseline-performance.adoc[Module 3 - Baseline Testing] +
4. **Core Optimization**: xref:module-04-core-performance-tuning.adoc[Module 4 - Performance Tuning] +

**Additional Resources:** +
* link:https://docs.openshift.com/container-platform/4.20/scalability_and_performance/what-huge-pages-do-and-how-they-are-consumed-by-apps.html[OpenShift Performance Documentation^] +
* link:https://github.com/cloud-bulldozer/kube-burner[Kube-burner Performance Testing^] +
* link:https://docs.openshift.com/container-platform/latest/virt/about-virt.html[OpenShift Virtualization Documentation^] +

== Requirements for the Lab Environment

**Prerequisites:** +
* Single Node OpenShift (SNO) 4.20+ cluster with cluster-admin privileges +
* SSH access to bastion host (pre-configured) +
* Terminal access with `oc` CLI configured (pre-configured on bastion) +
* Basic understanding of Kubernetes/OpenShift concepts +

**Hardware Recommendations:** +
* Worker nodes with dedicated CPU cores (minimum 8 cores per node) +
* At least 32GB RAM per worker node for performance testing +
* SR-IOV capable network interfaces (for Module 5) +
* NVMe storage for optimal I/O performance +
