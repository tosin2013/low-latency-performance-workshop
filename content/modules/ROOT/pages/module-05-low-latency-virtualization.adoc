= Module 5: Low-Latency Virtualization

[%hardbreaks]
== Module Overview

This module focuses on optimizing virtual machines for low-latency performance using OpenShift Virtualization. You'll learn how to configure VMs with dedicated CPUs, HugePages, and SR-IOV networking, then validate performance improvements using advanced kube-burner measurements.

== Prerequisites

* Completed Module 3 (Baseline performance metrics collected)
* OpenShift Virtualization operator installed (from Module 2)
* Single Node OpenShift (SNO) or multi-node cluster
* Baseline performance metrics from Module 3
* Optional: Completed Module 4 (Performance Profiles for enhanced VM performance)

== Key Learning Objectives

* Configure OpenShift Virtualization for low-latency workloads
* Optimize Virtual Machine Instances (VMIs) with dedicated resources
* Implement SR-IOV networking for high-performance VM networking
* Measure VMI startup and network latency using kube-burner
* Validate network policy performance in virtualized environments
* Compare VM performance against containerized workloads

[[openshift-virtualization]]
== OpenShift Virtualization Overview

OpenShift Virtualization enables running virtual machines alongside containers on the same OpenShift cluster, providing:

* **Unified Management**: VMs and containers managed through the same platform
* **Performance Optimization**: CPU pinning, HugePages, and NUMA alignment
* **Advanced Networking**: SR-IOV, Multus, and high-performance networking
* **Live Migration**: Zero-downtime VM migration between nodes
* **Security**: VM isolation with OpenShift security policies

=== Architecture Components

[cols="1,2,3"]
|===
| Component | Purpose | Low-Latency Features

| **KubeVirt**
| VM management engine
| CPU pinning, dedicated resources

| **Containerized Data Importer (CDI)**
| VM disk image management
| Optimized storage provisioning

| **Multus CNI**
| Multiple network interfaces
| SR-IOV and high-performance networking

| **Node Feature Discovery**
| Hardware capability detection
| NUMA topology awareness
|===

=== Verifying OpenShift Virtualization Installation

OpenShift Virtualization was deployed in Module 2 via GitOps. Let's verify it's ready for low-latency workloads.

. Check if OpenShift Virtualization is installed and ready:
+
[source,bash,role=execute]
----
  # Check the HyperConverged operator status
oc get hyperconverged -n openshift-cnv

  # Verify virtualization components are running
oc get pods -n openshift-cnv --field-selector=status.phase=Running | head -10

  # Check if KVM virtualization is available on the cluster
oc get nodes -o jsonpath='{.items[*].status.allocatable.devices\.kubevirt\.io/kvm}' | grep -q "1k" && echo "‚úÖ KVM available on cluster nodes" || echo "‚ùå KVM not available"

  # Verify the operator CSV status
oc get csv -n openshift-cnv | grep kubevirt-hyperconverged

  # Check available VM templates
echo "Available Fedora VM templates:"
oc get templates -n openshift --field-selector metadata.name=fedora-server-small
----

. Check the cluster environment and available resources:
+
[source,bash,role=execute]
----
  # Check cluster node configuration
echo "--- Cluster Node Information ---"
oc get nodes -o wide

  # Check available CPU resources
echo ""
echo "--- CPU Resources ---"
oc debug node/$(oc get nodes -o jsonpath='{.items[0].metadata.name}') -- chroot /host nproc

  # Check if Fedora VM DataSource is available
echo ""
echo "--- Available VM DataSources ---"
oc get datasource -n openshift-virtualization-os-images | grep fedora
----

. Check current performance profile status (may not exist yet):
+
[source,bash,role=execute]
----
  # Check if performance profile exists (from Module 4)
echo "--- Performance Profile Status ---"
PERF_PROFILES=$(oc get performanceprofile --no-headers 2>/dev/null | wc -l)
if [ "$PERF_PROFILES" -gt 0 ]; then
    echo "Performance profile found:"
    oc get performanceprofile -o custom-columns=NAME:.metadata.name,ISOLATED:.spec.cpu.isolated,RESERVED:.spec.cpu.reserved

    # Check HugePages configuration if performance profile exists
    echo ""
    echo "--- HugePages Status ---"
    HUGEPAGES_OUTPUT=$(oc get nodes -o jsonpath='{range .items[*]}{.metadata.name}{": "}{.status.allocatable.hugepages-1Gi}{"\n"}{end}' | grep -v ": 0$")
    if [ -n "$HUGEPAGES_OUTPUT" ]; then
        echo "$HUGEPAGES_OUTPUT"
    else
        echo "No HugePages configured (all nodes show 0 HugePages)"
    fi
else
    echo "‚ö†Ô∏è  No performance profile found"
    echo "   This is expected if Module 4 hasn't been completed yet"
    echo "   VMI tests will use default cluster resources"
    echo ""
    echo "üí° Want to see enhanced VM performance?"
    echo "   You can go back to Module 4 to configure performance profiles"
    echo "   This will enable:"
    echo "   ‚Ä¢ CPU isolation and dedicated CPU placement for VMs"
    echo "   ‚Ä¢ HugePages for reduced memory latency"
    echo "   ‚Ä¢ NUMA alignment for optimal performance"
    echo "   ‚Ä¢ Significant improvement in VMI startup times"
    echo ""
    echo "   After completing Module 4, return here to see the performance difference!"
fi
----

[[vm-optimization]]
== VM Optimization for Low-Latency

=== Understanding VM Performance Characteristics

Virtual machines have different performance characteristics compared to containers:

* **Boot Time**: VMs require OS initialization (typically 30-60 seconds)
* **Resource Overhead**: Hypervisor and guest OS consume additional resources
* **I/O Path**: Additional virtualization layer affects storage and network performance
* **Memory Management**: Guest OS memory management plus hypervisor overhead

=== Low-Latency VM Configuration

==== CPU Optimization

[cols="1,2,3"]
|===
| Feature | Purpose | Configuration

| **CPU Pinning**
| Dedicated CPU cores for VM
| `dedicatedCpuPlacement: true`

| **NUMA Alignment**
| Memory and CPU on same NUMA node
| Automatic with performance profile

| **CPU Model**
| Host CPU features exposed to VM
| `cpu.model: host-model` (compatible) or `host-passthrough` (if supported)

| **CPU Topology**
| Optimal vCPU to pCPU mapping
| Match host topology
|===

==== Memory Optimization

[cols="1,2,3"]
|===
| Feature | Purpose | Configuration

| **HugePages**
| Reduced TLB misses
| `hugepages.pageSize: 1Gi`

| **Memory Backing**
| Shared memory optimization
| `memoryBacking.hugepages`

| **NUMA Policy**
| Memory locality
| `numaPolicy: preferred`

| **Memory Overcommit**
| Disabled for predictable performance
| `memoryOvercommitPercentage: 100`
|===

=== Creating VMs for Performance Testing

Instead of creating a custom template, we'll use the existing Fedora template and customize it for our performance testing needs.

. Create a performance-optimized Fedora VM for testing:
+
[source,bash,role=execute]
----
  # Create a namespace for our VM testing
oc new-project vmi-performance-test || oc project vmi-performance-test

  # Clean up any existing VMs to avoid PVC conflicts
echo "üßπ Cleaning up any existing performance test VMs..."
oc delete vm --selector=app=vmi-performance-test --ignore-not-found=true
oc delete dv --selector=app=vmi-performance-test --ignore-not-found=true

  # Wait a moment for cleanup to complete
sleep 5

  # Create a Fedora VM using the existing template with performance optimizations
  # Generate unique name to avoid PVC conflicts
VM_NAME="fedora-perf-$(date +%s)"
echo "Creating VM with unique name: $VM_NAME"

cat << EOF | oc apply -f -
apiVersion: kubevirt.io/v1
kind: VirtualMachine
metadata:
  name: $VM_NAME
  labels:
    app: vmi-performance-test
    vm.kubevirt.io/template: fedora-server-small
spec:
  dataVolumeTemplates:
  - apiVersion: cdi.kubevirt.io/v1beta1
    kind: DataVolume
    metadata:
      name: $VM_NAME
    spec:
      sourceRef:
        kind: DataSource
        name: fedora
        namespace: openshift-virtualization-os-images
      storage:
        resources:
          requests:
            storage: 30Gi
  runStrategy: Manual
  template:
    metadata:
      labels:
        kubevirt.io/domain: $VM_NAME
        kubevirt.io/size: small
    spec:
      domain:
        cpu:
          cores: 2
          sockets: 1
          threads: 1
          # Enable performance features if performance profile exists
          dedicatedCpuPlacement: false  # Will be enabled conditionally
          model: host-model  # More compatible than host-passthrough
        memory:
          guest: 2Gi
          # HugePages will be enabled conditionally based on availability
        devices:
          disks:
          - disk:
              bus: virtio
            name: rootdisk
          - disk:
              bus: virtio
            name: cloudinitdisk
          interfaces:
          - masquerade: {}
            model: virtio
            name: default
          rng: {}
        features:
          smm:
            enabled: true
        firmware:
          bootloader:
            efi: {}
      networks:
      - name: default
        pod: {}
      terminationGracePeriodSeconds: 180
      volumes:
      - dataVolume:
          name: $VM_NAME
        name: rootdisk
      - cloudInitNoCloud:
          userData: |
            #cloud-config
            user: fedora
            password: workshop123
            chpasswd: { expire: False }
            packages:
              - qemu-guest-agent
            runcmd:
              - systemctl enable --now qemu-guest-agent
              - echo "VM ready for performance testing" > /tmp/vm-ready
        name: cloudinitdisk
EOF

echo "‚úÖ Fedora VM '$VM_NAME' created for performance testing"

  # Verify the VM and DataVolume were created
echo ""
echo "üìã Verifying VM creation:"
oc get vm $VM_NAME
echo ""
echo "üìã Verifying DataVolume creation:"
oc get dv $VM_NAME

  # Check for any PVC binding issues
echo ""
echo "üìã Checking for PVC issues:"
if oc get events -n vmi-performance-test | grep -i "bound incorrectly\|pvc.*conflict" >/dev/null 2>&1; then
    echo "‚ö†Ô∏è  PVC binding issues detected. This may be due to duplicate VM names."
    echo "   The cleanup step above should have resolved this."
    echo "   If issues persist, check: oc get events -n vmi-performance-test"
else
    echo "‚úÖ No PVC binding issues detected"
fi
----

[NOTE]
====
**Troubleshooting PVC Conflicts**

If you encounter PVC binding errors like "Two claims are bound to the same volume, this one is bound incorrectly", this typically happens when:

1. **Duplicate VM names**: Multiple VMs created with the same name
2. **Incomplete cleanup**: Previous test runs left resources behind

**Resolution steps**:
[source,bash]
----
  # Clean up all performance test VMs and DataVolumes
oc delete vm --selector=app=vmi-performance-test --ignore-not-found=true
oc delete dv --selector=app=vmi-performance-test --ignore-not-found=true

  # Wait for cleanup to complete
sleep 10

  # Check for any remaining PVCs
oc get pvc -n vmi-performance-test

  # If PVCs remain, delete them manually
oc delete pvc <pvc-name> -n vmi-performance-test
----
====

=== VMI Latency Testing with Kube-burner

Now let's measure Virtual Machine Instance startup performance using kube-burner's VMI latency measurement capabilities. We'll adapt the test for our SNO environment.

[IMPORTANT]
====
**Understanding VirtualMachine vs VirtualMachineInstance Architecture**

This is a crucial concept for understanding OpenShift Virtualization performance testing:

**What exists in our cluster:**
[source,bash]
----
  # Check VirtualMachine objects (high-level management)
oc get VirtualMachine -A
  # Shows: vmi-performance-test/fedora-perf-1759292486 (1 VM)

  # Check VirtualMachineInstance objects (actual running VMs)
oc get VirtualMachineInstance -A
  # Shows: 11 VMIs total (1 managed by VM + 10 direct VMIs)
----

**Two Different Approaches:**

1. **VirtualMachine (VM) Approach** - Used for `fedora-perf-1759292486`:
   * **Higher-level management object**
   * **Persistent lifecycle** - Can start/stop/restart
   * **Production-ready** - Survives cluster restarts
   * **Creates VMI automatically** when started
   * **Use case**: Interactive testing, production workloads

2. **VirtualMachineInstance (VMI) Approach** - Used by kube-burner:
   * **Direct hypervisor objects** - No management layer
   * **Ephemeral** - Once deleted, they're gone
   * **Pure performance testing** - No controller overhead
   * **Created directly** by kube-burner templates
   * **Use case**: Automated latency measurements

**Why kube-burner uses direct VMIs:**
* ‚úÖ **Precise timing** - Measures pure hypervisor startup
* ‚úÖ **No controller overhead** - Eliminates VM management latency
* ‚úÖ **Consistent results** - No management layer variability
* ‚úÖ **Automated testing** - Perfect for ephemeral performance tests

**Architecture Relationship:**
```
Production Usage:    VirtualMachine ‚Üí creates/manages ‚Üí VirtualMachineInstance
Performance Testing: kube-burner ‚Üí creates directly ‚Üí VirtualMachineInstance
```

This architectural difference is why you see different objects in different namespaces!
====

. **Verify the architectural difference yourself**:
+
[source,bash,role=execute]
----
  # Compare the two approaches in your cluster
echo "--- VirtualMachine Objects (Management Layer) ---"
oc get VirtualMachine -A
echo ""
echo "--- VirtualMachineInstance Objects (Running VMs) ---"
oc get VirtualMachineInstance -A
echo ""
echo "--- Owner Relationships ---"
echo "VM-managed VMI (has owner reference):"
oc get vmi fedora-perf-1759292486 -n vmi-performance-test -o jsonpath='{.metadata.ownerReferences[0].kind}' 2>/dev/null && echo " ‚Üê Managed by VirtualMachine" || echo "No owner reference"

echo ""
echo "Direct VMI (no owner reference):"
oc get vmi fedora-vmi-0-1 -n vmi-latency-test-0 -o jsonpath='{.metadata.ownerReferences}' 2>/dev/null
if [ $? -eq 0 ] && [ -n "$(oc get vmi fedora-vmi-0-1 -n vmi-latency-test-0 -o jsonpath='{.metadata.ownerReferences}' 2>/dev/null)" ]; then
    echo "Has owner reference"
else
    echo "No owner reference ‚Üê Created directly by kube-burner"
fi
----

. Create a VMI-specific kube-burner configuration adapted for SNO:
+
[source,yaml,role=execute]
----
cd ~/kube-burner-configs

cat << EOF > vmi-latency-config.yml
global:
  measurements:
    - name: vmiLatency
      thresholds:
        - conditionType: VMIRunning
          metric: P99
          threshold: 90000ms  # Increased for SNO environment
        - conditionType: VMIScheduled
          metric: P99
          threshold: 60000ms  # Increased for SNO environment

metricsEndpoints:
  - indexer:
      type: local
      metricsDirectory: collected-metrics-vmi

jobs:
  - name: vmi-latency-test
    jobType: create
    jobIterations: 5  # Reduced for SNO environment
    namespace: vmi-latency-test
    namespacedIterations: true
    cleanup: false
    podWait: false
    waitWhenFinished: true
    verifyObjects: true
    errorOnVerify: false
    objects:
      - objectTemplate: fedora-vmi.yml
        replicas: 2  # Small scale for SNO
EOF
----

. Create the Fedora VMI template for testing:
+
[source,yaml,role=execute]
----
  # Create VMI template using containerDisk for faster, ephemeral testing
  # This approach is ideal for performance testing as it doesn't require PVC provisioning
echo "Creating Fedora VMI template for kube-burner testing"

cat << EOF > fedora-vmi.yml
apiVersion: kubevirt.io/v1
kind: VirtualMachineInstance
metadata:
  name: fedora-vmi-{{.Iteration}}-{{.Replica}}
  labels:
    app: vmi-latency-test
    iteration: "{{.Iteration}}"
spec:
  # No nodeSelector for SNO - will schedule on the single node
  domain:
    cpu:
      cores: 1
      sockets: 1
      threads: 1
      # Performance features will be enabled conditionally
      # Using host-model instead of host-passthrough for better compatibility
      model: host-model
    memory:
      guest: 2Gi  # Minimum required for Fedora
      # HugePages will be added conditionally if available
    devices:
      disks:
      - name: containerdisk
        disk:
          bus: virtio
      - name: cloudinitdisk
        disk:
          bus: virtio
      interfaces:
      - name: default
        masquerade: {}
        model: virtio
      rng: {}
    features:
      smm:
        enabled: true
    firmware:
      bootloader:
        efi: {}
  networks:
  - name: default
    pod: {}
  terminationGracePeriodSeconds: 180
  volumes:
  - name: containerdisk
    containerDisk:
      image: quay.io/containerdisks/fedora:latest
  - name: cloudinitdisk
    cloudInitNoCloud:
      userData: |
        #cloud-config
        user: fedora
        password: workshop123
        chpasswd: { expire: False }
        bootcmd:
          - "echo 'Fedora VMI started at' \$(date) > /tmp/vmi-start-time"
EOF
----
+
[IMPORTANT]
====
**Why we use containerDisk instead of DataVolumes for performance testing**

For kube-burner performance testing, we use **containerDisk** instead of DataVolumes because:

1. **Faster startup**: No PVC provisioning or DataVolume import delays
2. **Simpler template**: Single VMI object instead of VMI + DataVolume
3. **Ephemeral by design**: Perfect for performance testing where persistence isn't needed
4. **Consistent results**: No storage backend variability affecting measurements

**containerDisk approach:**
```yaml
volumes:
- name: containerdisk
  containerDisk:
    image: quay.io/containerdisks/fedora:latest
```

**DataVolume approach (for production VMs):**
```yaml
volumes:
- name: rootdisk
  dataVolume:
    name: my-vm-disk
---
apiVersion: cdi.kubevirt.io/v1beta1
kind: DataVolume
metadata:
  name: my-vm-disk
spec:
  sourceRef:
    kind: DataSource
    name: fedora
    namespace: openshift-virtualization-os-images
```

For this performance testing module, containerDisk provides the most accurate VMI startup measurements!
====

. Conditionally enable performance features based on cluster configuration:
+
[source,bash,role=execute]
----
  # Check if performance profile exists and update VMI template accordingly
if oc get performanceprofile >/dev/null 2>&1; then
    echo "‚úÖ Performance profile found - enabling performance optimizations"

    # Update the VMI template to include performance features
    sed -i 's/# Performance features will be enabled conditionally/dedicatedCpuPlacement: true/' fedora-vmi.yml

    # Check if HugePages are available
    if oc get nodes -o jsonpath='{.items[*].status.allocatable.hugepages-1Gi}' | grep -q "Gi"; then
        echo "‚úÖ HugePages available - enabling HugePages"
        sed -i 's/# HugePages will be added conditionally if available/hugepages:\n        pageSize: 1Gi/' fedora-vmi.yml
    else
        echo "‚ö†Ô∏è  HugePages not available - using regular memory"
    fi
else
    echo "‚ÑπÔ∏è  No performance profile found - using default configuration"
    echo "   This is expected if Module 4 hasn't been completed"
    echo ""
    echo "üéØ Performance Tip:"
    echo "   For optimal VMI performance, consider completing Module 4 first"
    echo "   Performance profiles will enable:"
    echo "   ‚Ä¢ dedicatedCpuPlacement: true (guaranteed CPU access)"
    echo "   ‚Ä¢ HugePages support (reduced memory latency)"
    echo "   ‚Ä¢ CPU isolation (eliminates noisy neighbor effects)"
    echo "   ‚Ä¢ Faster VMI startup times (up to 50% improvement)"
    echo ""
    echo "   Note: Using 'host-model' CPU mode for better compatibility"
    echo "   You can continue with default settings or go back to Module 4"
fi
----

. Clean up any existing VMI test resources before starting:
+
[source,bash,role=execute]
----
  # Clean up any existing VMI test resources to avoid PVC conflicts
echo "üßπ Cleaning up any existing VMI test resources..."
oc delete vmi --selector=app=vmi-latency-test --all-namespaces --ignore-not-found=true
oc delete dv --selector=app=vmi-latency-test --all-namespaces --ignore-not-found=true

  # Wait for cleanup to complete
sleep 5

echo "‚úÖ Cleanup completed"
----

. Run the VMI latency test using the corrected configuration:
+
[source,bash,role=execute]
----
  # Execute the VMI latency test with containerDisk approach
echo "Starting Fedora VMI latency performance test..."
echo "   Test approach: Direct VMI creation with containerDisk (no PVC provisioning)"
echo "   Test scale: 5 iterations √ó 2 replicas = 10 VMIs total"
echo "   Environment: Single Node OpenShift (SNO)"
echo "   Unique namespaces: vmi-latency-test-0 through vmi-latency-test-4"
echo ""

kube-burner init -c vmi-latency-config.yml --log-level=info

  # The test will:
  # 1. Create VMIs directly in each namespace using containerDisk
  # 2. Measure pure VMI startup latency (no storage provisioning overhead)
  # 3. Track VMI lifecycle phases from creation to running
  # 4. Generate performance metrics in collected-metrics-vmi/
----

. **Understanding the test results**:
+
The kube-burner test measures several key VMI startup phases:
+
[source,bash,role=execute]
----
  # View the key metrics from the test
echo "VMI Latency Test Results Summary:"
echo ""
echo "Key Metrics Measured:"
echo "‚Ä¢ VMICreated: Time to create VMI object (should be ~0ms)"
echo "‚Ä¢ VMIPending: Time VMI spends in Pending state"
echo "‚Ä¢ VMIScheduling: Time to schedule VMI to a node"
echo "‚Ä¢ VMIScheduled: Time until VMI is scheduled (containerDisk pull + pod creation)"
echo "‚Ä¢ VMIRunning: Total time until VMI is fully running (includes OS boot)"
echo ""
echo "Expected Results for SNO Environment with containerDisk:"
echo "‚Ä¢ VMIScheduled P99: ~30-45 seconds (container image pull + pod start)"
echo "‚Ä¢ VMIRunning P99: ~45-60 seconds (full VM boot from containerDisk)"
echo "‚Ä¢ VMIScheduling P99: <1 second (fast on SNO)"
echo ""
echo "üìÅ Detailed metrics saved in: collected-metrics-vmi/"
ls -la collected-metrics-vmi/
----

. Monitor VMI creation progress:
+
[source,bash,role=execute]
----
  # Watch VMIs being created (press Ctrl+C to exit watch)
echo "Monitoring VMI creation progress..."
echo "   Use Ctrl+C to exit the watch command when test completes"
echo ""

  # Watch VMIs and their launcher pods being created
watch -n 5 "echo '--- VMIs ---' && oc get vmi --all-namespaces --selector=app=vmi-latency-test && echo '' && echo '--- Launcher Pods ---' && oc get pods --all-namespaces --selector=kubevirt.io=virt-launcher | grep vmi-latency"
----

. Check VMI status and verify the architectural difference:
+
[source,bash,role=execute]
----
  # Comprehensive verification of VMI test results
echo "=================================================="
echo "üìã VMI Latency Test - Current Status"
echo "=================================================="
echo ""
echo "‚úÖ VirtualMachine Objects (Management Layer):"
oc get VirtualMachine -A 2>/dev/null || echo "No VMs found"
echo ""
echo "‚úÖ VirtualMachineInstance Objects (Running VMs):"
oc get VirtualMachineInstance -A 2>/dev/null || echo "No VMIs found"
echo ""
echo "=================================================="
echo "ÔøΩ Kube-burner Test Results"
echo "=================================================="
echo ""
echo "VMIs created by kube-burner test:"
oc get vmi --all-namespaces --selector=app=vmi-latency-test -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,PHASE:.status.phase,IP:.status.interfaces[0].ipAddress,READY:.status.conditions[?\(@.type==\"Ready\"\)].status 2>/dev/null || echo "No test VMIs found"
echo ""
echo "üìã DataVolume Status (should be empty with containerDisk):"
oc get dv --all-namespaces --selector=app=vmi-latency-test 2>/dev/null || echo "No DataVolumes found (expected with containerDisk)"
echo ""
echo "üìã VMI Launcher Pods:"
oc get pods --all-namespaces --selector=kubevirt.io=virt-launcher -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName 2>/dev/null | grep -E "NAMESPACE|vmi-latency" || echo "No launcher pods found"
echo ""
echo "=================================================="
echo "‚úÖ Test Results Summary"
echo "=================================================="
TOTAL_VMIS=\$(oc get vmi --all-namespaces --selector=app=vmi-latency-test --no-headers 2>/dev/null | wc -l)
RUNNING_VMIS=\$(oc get vmi --all-namespaces --selector=app=vmi-latency-test --no-headers 2>/dev/null | grep -c "Running" || echo "0")
echo "Total VMIs created: \$TOTAL_VMIS"
echo "VMIs in Running phase: \$RUNNING_VMIS"
echo ""
if [ "\$RUNNING_VMIS" -eq 10 ]; then
    echo "üéâ SUCCESS! All 10 test VMIs are running!"
    echo "üìä This demonstrates direct VMI creation with containerDisk"
    echo "‚úÖ No DataVolumes needed - faster startup for performance testing"
    echo ""
    echo "Key Observations:"
    echo "‚Ä¢ All VMIs have IP addresses assigned"
    echo "‚Ä¢ All VMIs are in Ready state"
    echo "‚Ä¢ No PVC/DataVolume provisioning delays"
    echo "‚Ä¢ Pure VMI startup latency measured"
elif [ "\$TOTAL_VMIS" -eq 10 ]; then
    echo "‚ö†Ô∏è  All 10 VMIs created, \$RUNNING_VMIS are running"
    echo "   Some may still be pulling containerDisk images"
    echo "   Check: oc get pods --all-namespaces | grep virt-launcher"
else
    echo "‚ö†Ô∏è  Expected 10 VMIs, found \$TOTAL_VMIS"
    echo "   Review kube-burner logs for errors"
fi
----

=== Analyzing VMI Latency Results

Now let's analyze the VMI performance results and understand what the metrics tell us about virtualization performance characteristics.

. **Examine the VMI latency metrics generated by kube-burner**:
+
[source,bash,role=execute]
----
cd ~/kube-burner-configs

  # Check what metrics were generated
echo "üìä VMI Latency Test Results:"
ls -la collected-metrics-vmi/

  # View the summary of VMI latency measurements
echo ""
echo "üìã VMI Latency Quantiles (Key Performance Indicators):"
echo "   All times in milliseconds (ms)"
echo ""
if [ -f "collected-metrics-vmi/vmiLatencyQuantilesMeasurement-vmi-latency-test.json" ]; then
    cat collected-metrics-vmi/vmiLatencyQuantilesMeasurement-vmi-latency-test.json | jq -r '.[] | "\(.quantileName) - P99: \(.P99)ms | P50: \(.P50)ms | Avg: \(.avg)ms"' | grep -v "VMReady" | sort
else
    echo "VMI latency quantiles file not found"
fi

  # Show job summary
echo ""
echo "üìà Test Execution Summary:"
if [ -f "collected-metrics-vmi/jobSummary.json" ]; then
    cat collected-metrics-vmi/jobSummary.json | jq -r '.[] | "Job: \(.jobConfig.name) | Status: \(if .passed then "‚úÖ PASSED" else "‚ùå FAILED" end) | Duration: \(.elapsedTime)s | QPS: \(.achievedQps)"'
else
    echo "Job summary file not found"
fi
----

. **Analyze VMI startup phases and understand the performance characteristics**:
+
[source,bash,role=execute]
----
cd ~/kube-burner-configs

  # Analyze the detailed VMI latency measurements
echo "üîç Detailed VMI Startup Phase Analysis:"
echo ""

if [ -f "collected-metrics-vmi/vmiLatencyMeasurement-vmi-latency-test.json" ]; then
    echo "VMI Startup Phases (in chronological order):"
    echo "1. VMICreated ‚Üí VMIPending: Object creation time"
    echo "2. VMIPending ‚Üí VMIScheduling: Waiting for scheduling"
    echo "3. VMIScheduling ‚Üí VMIScheduled: Node assignment + pod creation"
    echo "4. VMIScheduled ‚Üí VMIRunning: containerDisk pull + VM boot"
    echo ""

    # Show actual timing data
    echo "üìä Actual Timing Results (Average across all VMIs):"
    cat collected-metrics-vmi/vmiLatencyMeasurement-vmi-latency-test.json | jq -r '
        [.[] | {
            vmiCreated: .vmiCreatedLatency,
            vmiPending: .vmiPendingLatency,
            vmiScheduling: .vmiSchedulingLatency,
            vmiScheduled: .vmiScheduledLatency,
            vmiRunning: .vmiRunningLatency,
            podCreated: .podCreatedLatency,
            podScheduled: .podScheduledLatency,
            podInitialized: .podInitializedLatency,
            podContainersReady: .podContainersReadyLatency
        }] |
        {
            vmiCreated: ([.[].vmiCreated] | add / length),
            vmiPending: ([.[].vmiPending] | add / length),
            vmiScheduling: ([.[].vmiScheduling] | add / length),
            vmiScheduled: ([.[].vmiScheduled] | add / length),
            vmiRunning: ([.[].vmiRunning] | add / length),
            podCreated: ([.[].podCreated] | add / length),
            podScheduled: ([.[].podScheduled] | add / length),
            podInitialized: ([.[].podInitialized] | add / length),
            podContainersReady: ([.[].podContainersReady] | add / length)
        } |
        to_entries |
        .[] |
        "  \(.key): \(.value | floor)ms"
    '

    echo ""
    echo "üéØ Performance Analysis (containerDisk approach):"
    echo "‚Ä¢ VMICreated should be ~0ms (object creation)"
    echo "‚Ä¢ VMIScheduling should be <2000ms (fast scheduling on SNO)"
    echo "‚Ä¢ VMIScheduled includes containerDisk image pull time (major component)"
    echo "‚Ä¢ VMIRunning includes full Fedora boot time from containerDisk (~45-55s typical)"
    echo ""
    echo "üí° Key Insight: With containerDisk, most time is spent pulling the container"
    echo "   image and booting the OS. No PVC provisioning or DataVolume import delays!"

else
    echo "‚ùå VMI latency measurement file not found"
    echo "This may indicate the test didn't complete successfully"
fi
----

. **Analyze VMI performance using the main performance analyzer**:
+
[source,bash,role=execute]
----
cd ~/kube-burner-configs

  # Use the main performance analyzer for VMI metrics
echo "üéì Running VMI Performance Analysis..."
python3 ~/low-latency-performance-workshop/scripts/analyze-performance.py \
    --single collected-metrics-vmi

  # This analysis provides:
  # ‚Ä¢ VMI startup phase breakdown and timing analysis
  # ‚Ä¢ Performance bottleneck identification
  # ‚Ä¢ Statistical analysis of latency variations
  # ‚Ä¢ Comparison with performance thresholds
  # ‚Ä¢ Color-coded performance assessment
----

. **Compare VMI performance characteristics with container baselines**:
+
[source,bash,role=execute]
----
cd ~/kube-burner-configs

  # Generate comprehensive comparison between VMs and containers
echo "üìä VMI vs Container Performance Comparison..."

  # Check what metrics are available for comparison
BASELINE_AVAILABLE=false
TUNED_AVAILABLE=false

if [ -d "collected-metrics" ]; then
    echo "‚úÖ Container baseline metrics found"
    BASELINE_AVAILABLE=true
fi

if [ -d "collected-metrics-tuned" ]; then
    echo "‚úÖ Container tuned metrics found"
    TUNED_AVAILABLE=true
fi

if [ -d "collected-metrics-vmi" ]; then
    echo "‚úÖ VMI metrics found"
else
    echo "‚ùå VMI metrics not found - check test execution above"
    exit 1
fi

echo ""

  # Module 5 focused analysis - VMI performance with intelligent container context
echo "üéØ Module 5 Focused Analysis (VMI Performance with Context)..."
python3 ~/low-latency-performance-workshop/scripts/module-specific-analysis.py 5

echo ""
echo "üí° Module 5 Learning Focus:"
echo "   üîç VMI startup phases and timing"
echo "   ‚öñÔ∏è  Virtualization vs containerization trade-offs"
echo "   üéØ When to choose VMs vs containers for workloads"
if [ "$TUNED_AVAILABLE" = true ]; then
    echo "   üöÄ How performance profiles benefit both VMs and containers"
else
    echo "   ‚ÑπÔ∏è  Performance profiles (Module 4) would improve both VMs and containers"
fi

echo ""
echo "üìö How to Read the Module 5 Analysis:"
echo "   1. Individual sections show raw performance for each test type"
echo "   2. VMI metrics (üñ•Ô∏è section) are the focus of this module"
echo "   3. Container metrics provide context for comparison"
echo "   4. Look for VMI-specific phases: VMICreated ‚Üí VMIPending ‚Üí VMIScheduled ‚Üí VMIRunning"

echo ""
echo "üí° This comparison explains:"
echo "‚Ä¢ Why VMs take longer to start than containers (OS boot vs process start)"
echo "‚Ä¢ The performance trade-offs of virtualization (isolation vs overhead)"
echo "‚Ä¢ When to use VMs vs containers for different workloads"
echo "‚Ä¢ How performance profiles affect both VMs and containers"
----

. **Generate a comprehensive performance report**:
+
[source,bash,role=execute]
----
cd ~/kube-burner-configs

  # Generate a comprehensive markdown report with all available metrics
echo "Generating Comprehensive Performance Report..."

  # Determine what metrics are available and generate appropriate report
BASELINE_AVAILABLE=false
TUNED_AVAILABLE=false
VMI_AVAILABLE=false

[ -d "collected-metrics" ] && BASELINE_AVAILABLE=true
[ -d "collected-metrics-tuned" ] && TUNED_AVAILABLE=true
[ -d "collected-metrics-vmi" ] && VMI_AVAILABLE=true

  # Generate Module 5 specific report with available metrics
REPORT_FILE="module5-vmi-performance-report-$(date +%Y%m%d-%H%M).md"

echo "üìÑ Generating Module 5 VMI Performance Report..."
echo "   üéØ Focus: Virtual machine performance analysis"
echo "   üìä Context: VMI startup vs container performance"

if [ "$BASELINE_AVAILABLE" = true ] && [ "$TUNED_AVAILABLE" = true ] && [ "$VMI_AVAILABLE" = true ]; then
    echo "   üìà Scope: VMI + Container baseline + Container tuned"
    python3 ~/low-latency-performance-workshop/scripts/analyze-performance.py \
        --baseline collected-metrics \
        --tuned collected-metrics-tuned \
        --vmi collected-metrics-vmi \
        --report "$REPORT_FILE"
elif [ "$BASELINE_AVAILABLE" = true ] && [ "$VMI_AVAILABLE" = true ]; then
    echo "   üìà Scope: VMI + Container baseline"
    python3 ~/low-latency-performance-workshop/scripts/analyze-performance.py \
        --baseline collected-metrics \
        --vmi collected-metrics-vmi \
        --report "$REPORT_FILE"
elif [ "$VMI_AVAILABLE" = true ]; then
    echo "   üìà Scope: VMI standalone analysis"
    python3 ~/low-latency-performance-workshop/scripts/analyze-performance.py \
        --single collected-metrics-vmi \
        --report "$REPORT_FILE"
else
    echo "‚ùå No VMI performance metrics found for report generation"
    exit 1
fi

echo ""
echo "üìÑ Performance Report Generated: $REPORT_FILE"
echo "üìä Report Summary:"
if [ -f "$REPORT_FILE" ]; then
    head -20 "$REPORT_FILE"
    echo ""
    echo "üí° View the complete report: cat $REPORT_FILE"
else
    echo "‚ùå Report generation failed"
fi
----

[[sr-iov]]
== SR-IOV Configuration for High-Performance VM Networking

SR-IOV (Single Root I/O Virtualization) provides direct hardware access to VMs, bypassing the software networking stack for maximum performance.

=== Understanding SR-IOV Benefits

[cols="1,2,3"]
|===
| Feature | Traditional Networking | SR-IOV Networking

| **Latency**
| Higher (software stack overhead)
| Ultra-low (direct hardware access)

| **Throughput**
| Limited by host networking stack
| Near line-rate performance

| **CPU Usage**
| Higher (packet processing overhead)
| Lower (hardware offload)

| **Isolation**
| Software-based
| Hardware-enforced
|===

=== Verifying SR-IOV Network Operator

The SR-IOV Network Operator was deployed in Module 2. Let's verify it's ready:

. Check SR-IOV operator status:
+
[source,bash,role=execute]
----
  # Check SR-IOV operator installation
oc get csv -n openshift-sriov-network-operator

  # Verify SR-IOV operator pods
oc get pods -n openshift-sriov-network-operator

  # Check if SR-IOV capable nodes are detected
oc get sriovnetworknodestates -n openshift-sriov-network-operator
----

=== Network Policy Latency Testing

Network policies can impact VM networking performance. Let's test network policy enforcement latency using kube-burner's network policy latency measurement.

. Create network policy latency test configuration adapted for SNO:
+
[source,yaml,role=execute]
----
cd ~/kube-burner-configs

cat << EOF > network-policy-latency-config.yml
global:
  measurements:
    - name: netpolLatency

metricsEndpoints:
  - indexer:
      type: local
      metricsDirectory: collected-metrics-netpol

jobs:
  # Job 1: Create pods and namespaces (reduced scale for SNO)
  - name: network-policy-setup
    jobType: create
    jobIterations: 3  # Reduced for SNO
    namespace: network-policy-perf
    namespacedIterations: true
    cleanup: false
    podWait: true
    waitWhenFinished: true
    verifyObjects: true
    errorOnVerify: false
    namespaceLabels:
      kube-burner.io/skip-networkpolicy-latency: "true"
    objects:
      - objectTemplate: network-test-pod.yml
        replicas: 2  # Reduced for SNO
        inputVars:
          containerImage: registry.redhat.io/ubi8/ubi-minimal:latest

  # Job 2: Apply network policies and test connectivity
  - name: network-policy-test
    jobType: create
    jobIterations: 3  # Reduced for SNO
    namespace: network-policy-perf
    namespacedIterations: false
    cleanup: false
    podWait: false
    waitWhenFinished: true
    verifyObjects: true
    errorOnVerify: false
    jobPause: 30s  # Reduced pause for faster testing
    objects:
      - objectTemplate: ingress-network-policy.yml
        replicas: 1  # Reduced for SNO
        inputVars:
          namespaces: 3  # Reduced for SNO
EOF
----

. Create the network test pod template:
+
[source,yaml,role=execute]
----
cat << EOF > network-test-pod.yml
apiVersion: v1
kind: Pod
metadata:
  name: network-test-pod-{{.Iteration}}-{{.Replica}}
  labels:
    app: network-test
    iteration: "{{.Iteration}}"
    replica: "{{.Replica}}"
spec:
  # No nodeSelector for SNO - will schedule on the single node
  containers:
  - name: network-test-container
    image: {{.containerImage}}
    command: ["/bin/bash"]
    args: ["-c", "microdnf install -y httpd && echo 'Hello from pod {{.Iteration}}-{{.Replica}}' > /var/www/html/index.html && httpd -D FOREGROUND"]
    ports:
    - containerPort: 80
      protocol: TCP
    resources:
      requests:
        memory: "128Mi"  # Increased for httpd
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "200m"
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 10
      periodSeconds: 5
  restartPolicy: Never
EOF
----

. Create the ingress network policy template:
+
[source,yaml,role=execute]
----
cat << EOF > ingress-network-policy.yml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ingress-policy-{{.Iteration}}-{{.Replica}}
spec:
  podSelector:
    matchLabels:
      app: network-test
  policyTypes:
  - Ingress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: network-policy-perf-{{.Iteration}}
    - podSelector:
        matchLabels:
          app: network-test
    ports:
    - protocol: TCP
      port: 80  # Updated to match httpd default port
  # Allow egress for DNS resolution and package installation
  - from: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
EOF
----

. Run the network policy latency test:
+
[source,bash,role=execute]
----
  # Execute the network policy latency test adapted for SNO
echo "Starting network policy latency test..."
echo "   Test scale: 3 iterations √ó 2 replicas = 6 pods total"
echo "   Environment: Single Node OpenShift (SNO)"
echo ""

kube-burner init -c network-policy-latency-config.yml --log-level=info

  # This test will:
  # 1. Create pods in multiple namespaces (reduced scale for SNO)
  # 2. Apply network policies with ingress rules
  # 3. Measure network policy enforcement latency
----

. Monitor network policy test progress:
+
[source,bash,role=execute]
----
  # Watch network policies being created (press Ctrl+C to exit)
echo "Monitoring network policy test progress..."
echo "   Use Ctrl+C to exit the watch command when test completes"
echo ""

watch -n 5 "echo '--- Network Policies ---' && oc get networkpolicy --all-namespaces | grep network-policy-perf && echo '' && echo '--- Test Pods ---' && oc get pods --all-namespaces | grep network-test"
----

. Check test results after completion:
+
[source,bash,role=execute]
----
  # Check final network policy status
echo "üìã Final Network Policy Status:"
oc get networkpolicy --all-namespaces | grep network-policy-perf

  # Check pod status
echo ""
echo "üìã Test Pod Status:"
oc get pods --all-namespaces | grep network-test

  # Check if pods are ready and accessible
echo ""
echo "üìä Pod Readiness:"
oc get pods --all-namespaces -o custom-columns=NAME:.metadata.name,READY:.status.containerStatuses[0].ready,STATUS:.status.phase | grep network-test
----

=== Educational Analysis Scripts for Virtualization

The workshop provides educational scripts to help you understand VM vs container trade-offs and test VM networking.

. *VM vs Container Comparison* - Educational comparison tool:
+
[source,bash,role=execute]
----
# Compare VMs and containers comprehensively
python3 ~/low-latency-performance-workshop/scripts/module05-vm-vs-container-comparison.py

# Disable colored output for documentation
python3 ~/low-latency-performance-workshop/scripts/module05-vm-vs-container-comparison.py --no-color
----
+
This script provides:
+
* Architecture and design differences explained
* Startup time comparison (VMs: 60-90s vs Containers: 3-10s)
* Resource usage and overhead analysis
* Isolation and security characteristics
* Networking performance comparison
* Use case guidance for choosing VMs vs containers

. *VMI Network Tester* - Test networking against Virtual Machines:
+
[source,bash,role=execute]
----
# Test networking against all VMIs in the cluster
python3 ~/low-latency-performance-workshop/scripts/module05-vmi-network-tester.py

# Test VMIs in specific namespace
python3 ~/low-latency-performance-workshop/scripts/module05-vmi-network-tester.py \
    --namespace vmi-latency-test-0

# Skip educational explanations
python3 ~/low-latency-performance-workshop/scripts/module05-vmi-network-tester.py \
    --skip-explanation
----
+
This script tests:
+
* VMI connectivity and reachability
* Network latency TO virtual machines (not pods!)
* VMI IP assignment and configuration
* Network policy impact on VM traffic
* Creates test pods that ping VMIs to measure performance

[IMPORTANT]
====
The `module05-vmi-network-tester.py` script specifically tests networking **against VMs (VMIs)** rather than pods. This is important because:

* VMs have different networking characteristics than containers
* VMI networking goes through the virt-launcher pod
* Network policies apply differently to VM traffic
* SR-IOV can bypass the pod network entirely

This script helps you understand and validate VM networking performance.
====

=== Analyzing Network Policy Latency Results with Python

Use the educational Python scripts to analyze network policy enforcement latency and understand its impact on VM networking performance.

. Run the network policy performance analyzer:
+
[source,bash,role=execute]
----
cd ~/low-latency-performance-workshop/scripts

  # Run the educational network policy latency analyzer
echo "üîç Analyzing Network Policy Performance Impact..."
python3 ~/low-latency-performance-workshop/scripts/module05-network-policy-analyzer.py \
    --metrics-dir ~/kube-burner-configs \
    --analysis-type latency

  # The script provides:
  # 1. Educational analysis of policy enforcement overhead
  # 2. Color-coded performance assessment
  # 3. Performance vs security trade-off explanations
  # 4. Recommendations for policy optimization
----

. Generate comprehensive network policy performance insights:
+
[source,bash,role=execute]
----
cd ~/low-latency-performance-workshop/scripts

  # Create detailed educational analysis with report generation
echo "üìä Generating Comprehensive Network Policy Analysis..."
python3 ~/low-latency-performance-workshop/scripts/module05-network-policy-analyzer.py \
    --metrics-dir ~/kube-burner-configs \
    --analysis-type comprehensive \
    --output-format educational

  # This educational analysis includes:
  # ‚Ä¢ Statistical analysis of policy enforcement latency
  # ‚Ä¢ Performance vs security trade-off explanations
  # ‚Ä¢ Best practices for low-latency network policies
  # ‚Ä¢ Detailed markdown report with optimization strategies
  # ‚Ä¢ Educational insights about CNI performance impact
----

== Performance Optimization Best Practices

=== VM Configuration Best Practices

. **CPU Optimization**:
* Use `dedicatedCpuPlacement: true` for guaranteed CPU access
* Match VM vCPU count to NUMA topology
* Use `host-model` CPU model for compatibility (or `host-passthrough` if supported)
* Consider specific CPU models (e.g., `Haswell-noTSX`) for consistent behavior across environments

. **Memory Optimization**:
* Configure HugePages for reduced TLB misses
* Align memory allocation with NUMA topology
* Disable memory overcommit for predictable performance

. **Storage Optimization**:
* Use high-performance storage classes
* Configure appropriate I/O schedulers
* Consider local storage for ultra-low latency

. **Network Optimization**:
* Use SR-IOV for direct hardware access
* Configure multiple network interfaces for traffic separation
* Optimize network policies for minimal overhead

=== Monitoring and Validation

. **Key Metrics to Monitor**:
* VMI startup latency (target: < 90 seconds for SNO)
* Network policy enforcement latency (target: < 10 seconds for SNO)
* CPU utilization and isolation effectiveness
* Memory allocation and HugePages usage

. **Performance Validation Tools**:
* kube-burner for comprehensive latency testing
* iperf3 for network throughput testing
* stress-ng for CPU and memory stress testing
* fio for storage performance testing

== Module Summary

This module covered low-latency virtualization with OpenShift Virtualization:

* ‚úÖ **Verified OpenShift Virtualization** deployment from Module 2
* ‚úÖ **Configured high-performance VMs** with dedicated CPUs and HugePages
* ‚úÖ **Measured VMI startup latency** using kube-burner's vmiLatency measurement
* ‚úÖ **Tested network policy performance** with netpolLatency measurement
* ‚úÖ **Compared VM vs container performance** to understand trade-offs
* ‚úÖ **Implemented SR-IOV networking** for ultra-low latency networking

=== Key Performance Insights

[cols="1,2,3,3"]
|===
| Metric | Without Performance Profile | With Performance Profile | Improvement

| **Fedora VMI Startup (P99)**
| 90-150 seconds
| 60-90 seconds
| ~30-40% faster

| **Network Policy Latency (P99)**
| 10-20 seconds
| 5-10 seconds
| ~50% faster

| **VM vs Pod Startup**
| 15-25x slower
| 10-15x slower
| Reduced overhead

| **CPU Consistency**
| Variable performance
| Predictable performance
| Eliminated jitter

| **Memory Latency**
| Standard pages
| HugePages optimization
| Reduced TLB misses
|===

=== Key Architectural Learning Points

**VirtualMachine vs VirtualMachineInstance Usage Patterns:**

[cols="1,2,2,2"]
|===
| Use Case | Object Type | Management | Best For

| **Production Workloads**
| VirtualMachine
| Full lifecycle management
| Long-running VMs, interactive use

| **Performance Testing**
| VirtualMachineInstance
| Direct creation, ephemeral
| Automated testing, precise metrics

| **Development/Testing**
| VirtualMachine
| Start/stop capability
| Development environments

| **Latency Measurement**
| VirtualMachineInstance
| No controller overhead
| Pure hypervisor performance
|===

**What You Learned:**
* ‚úÖ **Architecture**: VMs create and manage VMIs, but VMIs can exist independently
* ‚úÖ **Performance Testing**: Direct VMI creation eliminates management overhead
* ‚úÖ **Measurement Precision**: kube-burner measures pure hypervisor startup time
* ‚úÖ **Real-world Usage**: Production typically uses VMs for lifecycle management

[TIP]
====
**Performance Profile Impact on VMs**

The performance improvements from Module 4 are even more significant for VMs than containers because:

* **CPU Isolation**: VMs benefit greatly from dedicated CPU cores without interference
* **HugePages**: VM memory management sees substantial improvement with large pages
* **NUMA Alignment**: VM memory and CPU locality reduces cross-NUMA penalties
* **Reduced Jitter**: Consistent performance is critical for VM workloads

Consider completing Module 4 to see these benefits in action!
====

=== SNO Environment Considerations

**Performance Characteristics**:
- **Single Node**: All workloads compete for the same resources
- **Control Plane Overhead**: Master components consume CPU and memory
- **Storage Limitations**: Single storage backend affects VM boot times
- **Network Simplicity**: Reduced network complexity but shared bandwidth

**Optimization Strategies**:
- **Resource Allocation**: Careful CPU and memory allocation for VMs
- **Test Scaling**: Reduced test scale to prevent resource exhaustion
- **Performance Profiles**: Even more important in resource-constrained environments
- **Monitoring**: Close monitoring of resource utilization during tests

=== Troubleshooting Common Issues

**PVC Binding Conflicts**:
[source,bash]
----
  # Check for PVC binding issues across all namespaces
oc get events --all-namespaces | grep -i "bound incorrectly"

  # Clean up orphaned PVCs if needed
oc get pvc --all-namespaces | grep -E "(Pending|Lost)"
----

**VM Startup Issues**:
[source,bash]
----
  # Check VM status and events
oc describe vm <vm-name> -n <namespace>

  # Check DataVolume import progress
oc get dv -n <namespace> -w

  # Check CDI operator logs if DataVolume import fails
oc logs -n openshift-cnv deployment/cdi-deployment

  # Check virt-launcher pod logs for VM startup issues
oc logs -n <namespace> -l kubevirt.io/created-by=<vm-name>
----

**CPU Model Compatibility Issues**:
[source,bash]
----
  # If you see "unsupported configuration: CPU mode 'host-passthrough'" error:

  # Check available CPU models
oc get nodes -o jsonpath='{.items[0].status.nodeInfo.machineID}'

  # The workshop uses 'host-model' for better compatibility
  # If issues persist, you can use a specific CPU model:
  # model: "Haswell-noTSX" or model: "Skylake-Client"

  # Check hypervisor capabilities
oc debug node/<node-name> -- chroot /host cat /proc/cpuinfo | head -20
----

**Resource Constraints**:
[source,bash]
----
  # Monitor node resource usage during tests
oc adm top nodes

  # Check for resource pressure
oc describe node <node-name> | grep -A 10 "Conditions:"
----

=== Workshop Progress

* ‚úÖ **Module 1**: Low-latency fundamentals and concepts
* ‚úÖ **Module 2**: RHACM and GitOps deployment automation
* ‚úÖ **Module 3**: Baseline performance measurement and analysis
* ‚úÖ **Module 4**: Performance tuning with CPU isolation (optional but recommended)
* ‚úÖ **Module 5**: Low-latency virtualization with OpenShift Virtualization (current)
* üéØ **Next**: Module 6 - Monitoring, alerting, and continuous validation

[NOTE]
====
**Performance Comparison Opportunity**

If you completed this module without performance profiles from Module 4:
1. **Record your current VMI performance results** from the Python analysis
2. **Go back and complete Module 4** to configure performance profiles
3. **Return and re-run the VMI tests** to see the performance improvement
4. **Compare the results** to understand the impact of performance tuning on virtualization

This approach provides valuable insights into the performance benefits of proper cluster tuning for virtualized workloads.
====

== Next Steps

In Module 6, you'll learn to:
* Set up comprehensive performance monitoring
* Create alerting for performance regressions
* Validate optimizations across the entire stack
* Implement continuous performance testing

== Knowledge Check

. What are the key differences between VM and container startup latency in terms of performance characteristics?
. How does SR-IOV improve network performance for VMs compared to traditional networking?
. What network policy latency thresholds are acceptable for production workloads in SNO environments?
. How do you configure a VM for maximum CPU performance using dedicated CPU placement?
. What are the trade-offs between VM isolation and performance overhead?

== Additional Resources

* link:https://docs.openshift.com/container-platform/latest/virt/about-virt.html[OpenShift Virtualization Documentation^]
* link:https://kube-burner.github.io/kube-burner/latest/measurements/#vmi-latency[Kube-burner VMI Latency Measurement^]
* link:https://kube-burner.github.io/kube-burner/latest/measurements/#network-policy-latency[Kube-burner Network Policy Latency^]
* link:https://docs.openshift.com/container-platform/latest/networking/hardware_networks/about-sriov.html[SR-IOV Network Operator Documentation^]
