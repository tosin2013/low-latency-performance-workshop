schemaVersion: 2.2.2
metadata:
  name: low-latency-workshop
  displayName: Low-Latency Performance Workshop
  description: |
    Development workspace for the Low-Latency Performance Workshop for OpenShift.
    Your SNO cluster credentials are automatically mounted.
    Access your personalized documentation at: https://docs-{username}.apps.{cluster-domain}
  version: 1.0.0
  tags:
    - OpenShift
    - Kubernetes
    - Performance
    - Low-Latency
    - Workshop
  icon: https://www.redhat.com/favicon.ico
  language: Shell
  projectType: workshop
attributes:
  controller.devfile.io/storage-type: per-user
  # Use the che-code editor from DevWorkspaceTemplate
  controller.devfile.io/editor-name: che-code
  .vscode/extensions.json: |
    {
      "recommendations": [
        "redhat.vscode-yaml",
        "ms-kubernetes-tools.vscode-kubernetes-tools"
      ]
    }

# Clone the workshop repository
projects:
  - name: workshop
    git:
      remotes:
        origin: https://github.com/tosin2013/low-latency-performance-workshop.git
      checkoutFrom:
        revision: feat/deployment-automation

# Main development container
components:
  # Note: che-code editor is injected automatically from DevWorkspaceTemplate
  
  - name: tools
    container:
      image: quay.io/devspaces/udi-rhel8:latest
      memoryLimit: 4Gi
      memoryRequest: 1Gi
      cpuLimit: "2"
      cpuRequest: 500m
      mountSources: true
      sourceMapping: /projects
      
      # Environment variables
      env:
        # Kubeconfig location (auto-mounted by Dev Spaces from labeled secret)
        - name: KUBECONFIG
          value: /home/user/.kube/config
        
        # Workshop configuration
        - name: WORKSHOP_HOME
          value: /projects/workshop
        
        # Add local bin to PATH for kube-burner and other tools
        - name: PATH
          value: /home/user/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
        
        # Ansible configuration
        - name: ANSIBLE_HOST_KEY_CHECKING
          value: "False"
        
        # Terminal colors
        - name: TERM
          value: xterm-256color

      # Volume mounts for workshop artifacts
      volumeMounts:
        - name: workshop-data
          path: /home/user/workshop-data
        # Note: SNO info ConfigMap is auto-mounted by Dev Spaces via labels:
        #   controller.devfile.io/mount-to-devworkspace: "true"
        #   controller.devfile.io/watch-configmap: "true"
        # The ConfigMap is created by 08-provision-complete-workshop.sh
        # and mounted at /home/user/sno-info
      
      # Endpoints (for any local services if needed)
      endpoints:
        - name: local-server
          targetPort: 8080
          exposure: public
          protocol: http

  # Persistent volume for workshop data
  - name: workshop-data
    volume:
      size: 2Gi
  
  # Note: checode volume is provided by the che-code DevWorkspaceTemplate

# Commands available in the workspace
commands:
  # Welcome message with user info and docs URL
  - id: show-workshop-info
    exec:
      label: "â˜… Workshop Info & Docs URL"
      component: tools
      workingDir: /projects/workshop
      commandLine: |
        echo ""
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘     LOW-LATENCY PERFORMANCE WORKSHOP                               â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        
        # Try to get cluster domain from current context
        if oc whoami &>/dev/null; then
          HUB_API=$(oc whoami --show-server 2>/dev/null || echo "unknown")
          HUB_DOMAIN=$(echo "$HUB_API" | sed 's|https://api\.||' | sed 's|:6443||')
          APPS_DOMAIN="apps.${HUB_DOMAIN}"
        else
          APPS_DOMAIN="apps.{your-cluster-domain}"
        fi
        
        # Get username from DevWorkspace or namespace
        if [ -n "$DEVWORKSPACE_NAMESPACE" ]; then
          # Extract username from namespace (e.g., user1-devspaces -> user1)
          USERNAME=$(echo "$DEVWORKSPACE_NAMESPACE" | sed 's/-devspaces$//')
        else
          USERNAME="{your-username}"
        fi
        
        # Check for SNO info from mounted ConfigMap
        if [ -f /home/user/sno-info/SNO_API_URL ]; then
          SNO_API=$(cat /home/user/sno-info/SNO_API_URL)
          SNO_CONSOLE=$(cat /home/user/sno-info/SNO_CONSOLE_URL 2>/dev/null || echo "")
          SNO_READY="âœ… Available"
        else
          SNO_API="https://api.workshop-${USERNAME}.{domain}:6443"
          SNO_CONSOLE="https://console-openshift-console.apps.workshop-${USERNAME}.{domain}"
          SNO_READY="â³ Check with admin if SNO is deployed"
        fi
        
        echo "  ğŸ“š YOUR PERSONALIZED DOCUMENTATION:"
        echo "     https://docs-${USERNAME}.${APPS_DOMAIN}"
        echo ""
        echo "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        echo ""
        echo "  ğŸ–¥ï¸  YOUR SNO CLUSTER:"
        echo "     API:     ${SNO_API}"
        echo "     Console: ${SNO_CONSOLE}"
        echo "     Status:  ${SNO_READY}"
        echo ""
        echo "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        echo ""
        echo "  ğŸ“ MOUNTED CREDENTIALS:"
        if [ -f /home/user/.kube/config ] && ! grep -q "Placeholder" /home/user/.kube/config 2>/dev/null; then
          echo "     âœ… Kubeconfig: /home/user/.kube/config"
        else
          echo "     â³ Kubeconfig: Pending (login manually with 'oc login')"
        fi
        if [ -f /home/user/.ssh/id_rsa ] && ! grep -q "Placeholder" /home/user/.ssh/id_rsa 2>/dev/null; then
          echo "     âœ… SSH Key: /home/user/.ssh/id_rsa"
        else
          echo "     â³ SSH Key: Pending"
        fi
        echo ""
        echo "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        echo ""
        echo "  ğŸš€ QUICK START:"
        echo "     1. Open your docs URL above in a new browser tab"
        echo "     2. Run 'oc get nodes' to verify cluster access"
        echo "     3. Follow the workshop modules in the docs"
        echo ""
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
      group:
        kind: run
        isDefault: true

  # Cluster safety check - ensures user is on SNO, not hub cluster
  - id: check-cluster-safety
    exec:
      label: "0. Check Cluster Safety"
      component: tools
      workingDir: /projects/workshop
      commandLine: |
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘  Cluster Safety Check                                      â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        
        # Check if logged in
        if ! oc whoami &>/dev/null; then
          echo "âš  Not logged into any cluster"
          echo ""
          echo "Please login to your SNO (target) cluster:"
          echo "  oc login https://api.<your-sno-cluster>:6443 -u kubeadmin -p <password>"
          exit 0
        fi
        
        CURRENT_SERVER=$(oc whoami --show-server 2>/dev/null)
        CURRENT_USER=$(oc whoami 2>/dev/null)
        
        echo "Current Context:"
        echo "  Server: $CURRENT_SERVER"
        echo "  User: $CURRENT_USER"
        echo ""
        
        # Check for hub cluster indicators
        IS_HUB=false
        
        # Check 1: RHACM ManagedCluster CRD exists (hub has this)
        if oc get crd managedclusters.cluster.open-cluster-management.io &>/dev/null; then
          # Check if there are managed clusters (hub manages others)
          MANAGED_COUNT=$(oc get managedclusters --no-headers 2>/dev/null | wc -l)
          if [ "$MANAGED_COUNT" -gt "0" ]; then
            IS_HUB=true
          fi
        fi
        
        # Check 2: Dev Spaces namespace exists (hub usually has this)
        if oc get namespace openshift-devspaces &>/dev/null; then
          # If devspaces exists AND managedclusters exist, likely hub
          if oc get crd managedclusters.cluster.open-cluster-management.io &>/dev/null; then
            IS_HUB=true
          fi
        fi
        
        # Check 3: Cluster name contains "hub" or common hub patterns
        if echo "$CURRENT_SERVER" | grep -qiE "(hub|rhacm|acm)"; then
          IS_HUB=true
        fi
        
        # Check 4: Single Node OpenShift check (SNO has only 1 node with master role)
        NODE_COUNT=$(oc get nodes --no-headers 2>/dev/null | wc -l)
        MASTER_WORKER=$(oc get nodes --no-headers 2>/dev/null | grep -c "master.*worker\|worker.*master" || echo "0")
        
        if [ "$IS_HUB" = true ]; then
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘  âš ï¸  WARNING: YOU ARE ON THE HUB CLUSTER!                   â•‘"
          echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
          echo "â•‘  Workshop modules should run on your SNO (target) cluster  â•‘"
          echo "â•‘  Running tests here could affect the management cluster!   â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "Please switch to your SNO cluster:"
          echo "  oc login https://api.<your-sno-cluster>:6443 -u kubeadmin -p <password>"
          echo ""
          echo "To find your SNO cluster credentials, check:"
          echo "  cat /home/user/sno-info/SNO_API 2>/dev/null"
          echo "  cat /home/user/sno-info/SNO_PASSWORD 2>/dev/null"
          exit 1
        elif [ "$NODE_COUNT" -eq "1" ] || [ "$MASTER_WORKER" -gt "0" ]; then
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘  âœ… Connected to SNO (Single Node OpenShift) cluster       â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "Node count: $NODE_COUNT"
          oc get nodes
        else
          echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
          echo "â•‘  âš ï¸  CLUSTER TYPE UNCLEAR                                   â•‘"
          echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "Node count: $NODE_COUNT"
          echo "Please verify this is your target cluster (not the hub)."
          oc get nodes
        fi
      group:
        kind: run
        isDefault: true

  # Verification commands
  - id: verify-sno-access
    exec:
      label: "1. Verify SNO Cluster Access"
      component: tools
      workingDir: /projects/workshop
      commandLine: |
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘  Verifying SNO Cluster Access                              â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        if [ -f /home/user/.kube/config ]; then
          echo "âœ“ Kubeconfig found at /home/user/.kube/config"
          echo ""
          echo "Cluster Info:"
          oc cluster-info 2>/dev/null || echo "âš  Cannot connect to cluster yet"
          echo ""
          echo "Nodes:"
          oc get nodes 2>/dev/null || echo "âš  Cannot get nodes"
        else
          echo "âœ— Kubeconfig not found"
          echo ""
          echo "To login manually to your SNO cluster (NOT the hub!):"
          echo "  oc login https://api.<your-sno-cluster>:6443 -u kubeadmin -p <password>"
        fi
      group:
        kind: run

  - id: verify-ssh-access
    exec:
      label: "2. Verify SSH Key"
      component: tools
      workingDir: /projects/workshop
      commandLine: |
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘  Verifying SSH Key                                         â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        if [ -f /home/user/.ssh/id_rsa ]; then
          echo "âœ“ SSH key found at /home/user/.ssh/id_rsa"
          chmod 600 /home/user/.ssh/id_rsa
          echo ""
          echo "SSH Key fingerprint:"
          ssh-keygen -lf /home/user/.ssh/id_rsa 2>/dev/null || echo "Could not read key"
        else
          echo "âœ— SSH key not found"
          echo "The SNO cluster may not be deployed yet."
        fi
      group:
        kind: run

  - id: check-environment
    exec:
      label: "3. Check Workshop Environment"
      component: tools
      workingDir: /projects/workshop
      commandLine: |
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘  Workshop Environment Check                                â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "Tools Available:"
        echo "  oc: $(oc version --client 2>/dev/null | head -1 || echo 'not found')"
        echo "  kubectl: $(kubectl version --client 2>/dev/null | head -1 || echo 'not found')"
        echo "  git: $(git --version 2>/dev/null || echo 'not found')"
        echo "  yq: $(yq --version 2>/dev/null || echo 'not found')"
        echo "  ansible: $(ansible --version 2>/dev/null | head -1 || echo 'not found')"
        echo ""
        echo "Environment Variables:"
        echo "  KUBECONFIG: ${KUBECONFIG:-not set}"
        echo "  WORKSHOP_HOME: ${WORKSHOP_HOME:-not set}"
        echo ""
        echo "Mounted Secrets:"
        [ -f /home/user/.kube/config ] && echo "  âœ“ Kubeconfig" || echo "  âœ— Kubeconfig (login manually with 'oc login')"
        [ -f /home/user/.ssh/id_rsa ] && echo "  âœ“ SSH Key" || echo "  âœ— SSH Key (pending)"
      group:
        kind: run

  # Module setup commands
  - id: setup-module02
    exec:
      label: "Module 02: Setup RHACM"
      component: tools
      workingDir: /projects/workshop
      commandLine: |
        echo "Running Module 02 RHACM Setup..."
        echo ""
        
        # Safety check - Module 02 actually runs on hub for RHACM setup
        # This is one of the few modules that needs hub access
        if ! oc whoami &>/dev/null; then
          echo "âŒ Not logged into any cluster. Please login first."
          exit 1
        fi
        
        echo "â„¹ï¸  Note: Module 02 configures RHACM on the hub cluster."
        echo "   Make sure you're logged into the correct cluster for this step."
        echo ""
        
        if [ -f workshop-scripts/09-setup-module02-rhacm.sh ]; then
          ./workshop-scripts/09-setup-module02-rhacm.sh
        else
          echo "Setup script not found. Manual setup required."
          echo "See: content/modules/ROOT/pages/module-02-rhacm-setup.adoc"
        fi
      group:
        kind: run

  # Open documentation (served by OpenShift)
  - id: open-docs
    exec:
      label: "ğŸ“š Open Workshop Documentation"
      component: tools
      workingDir: /projects/workshop
      commandLine: |
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘  Workshop Documentation                                    â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        echo "Your personalized workshop documentation is served by OpenShift."
        echo ""
        
        # Get username and cluster domain
        if [ -n "$DEVWORKSPACE_NAMESPACE" ]; then
          USERNAME=$(echo "$DEVWORKSPACE_NAMESPACE" | sed 's/-devspaces$//')
        else
          USERNAME="userN"
        fi
        
        if oc whoami &>/dev/null; then
          HUB_API=$(oc config view --minify -o jsonpath='{.clusters[0].cluster.server}' 2>/dev/null || oc whoami --show-server)
          APPS_DOMAIN=$(echo "$HUB_API" | sed 's|https://api\.||' | sed 's|:6443||' | sed 's/^/apps./')
        else
          APPS_DOMAIN="apps.{your-cluster}.{domain}"
        fi
        
        DOCS_URL="https://docs-${USERNAME}.${APPS_DOMAIN}"
        
        echo "  ğŸ“– YOUR DOCS URL:"
        echo ""
        echo "     ${DOCS_URL}"
        echo ""
        echo "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        echo ""
        echo "  Open this URL in your browser to access the workshop content."
        echo "  The documentation is personalized with your SNO cluster URLs."
        echo ""
        
        # Check if docs route exists
        if oc get route docs-${USERNAME} -n workshop-${USERNAME} &>/dev/null; then
          echo "  âœ… Documentation is deployed and ready!"
        else
          echo "  âš ï¸  Documentation route not found. Check with admin."
        fi
      group:
        kind: run

  # SSH to bastion
  - id: ssh-bastion
    exec:
      label: "SSH to Bastion"
      component: tools
      workingDir: /projects/workshop
      commandLine: |
        echo "Connecting to bastion..."
        if [ -f /home/user/.ssh/id_rsa ]; then
          chmod 600 /home/user/.ssh/id_rsa
          # Get bastion hostname from SNO info ConfigMap if available
          BASTION_HOST=$(cat /home/user/sno-info/BASTION_HOST 2>/dev/null || echo "bastion.workshop-student1.example.com")
          echo "Attempting SSH to: ec2-user@${BASTION_HOST}"
          ssh -o StrictHostKeyChecking=no -i /home/user/.ssh/id_rsa ec2-user@${BASTION_HOST}
        else
          echo "SSH key not available yet"
        fi
      group:
        kind: run

  # Install kube-burner
  - id: install-kube-burner
    exec:
      label: "Install kube-burner"
      component: tools
      workingDir: /home/user
      commandLine: |
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘  Installing kube-burner v1.17.5                            â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        if command -v kube-burner &> /dev/null; then
          echo "âœ“ kube-burner already installed"
          kube-burner version
        else
          echo "Downloading kube-burner..."
          mkdir -p ~/kube-burner
          cd ~/kube-burner
          curl -sL https://github.com/kube-burner/kube-burner/releases/download/v1.17.5/kube-burner-V1.17.5-linux-x86_64.tar.gz -o kube-burner.tar.gz
          tar -xzf kube-burner.tar.gz
          chmod +x kube-burner
          mv kube-burner /home/user/.local/bin/ 2>/dev/null || mkdir -p /home/user/.local/bin && mv kube-burner /home/user/.local/bin/
          rm -rf ~/kube-burner
          echo ""
          echo "âœ“ kube-burner installed successfully!"
          /home/user/.local/bin/kube-burner version
        fi
      group:
        kind: build

  # Run kube-burner baseline test
  - id: run-baseline-test
    exec:
      label: "Module 03: Run Baseline Test"
      component: tools
      workingDir: /projects/workshop/gitops/kube-burner-configs
      commandLine: |
        echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
        echo "â•‘  Module 03: Baseline Performance Test                      â•‘"
        echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        export PATH=$PATH:/home/user/.local/bin
        
        # Safety check - ensure we're on SNO, not hub
        if ! oc whoami &>/dev/null; then
          echo "âŒ Not logged into any cluster. Please login to your SNO cluster first."
          exit 1
        fi
        
        # Check for hub cluster indicators
        if oc get crd managedclusters.cluster.open-cluster-management.io &>/dev/null; then
          MANAGED_COUNT=$(oc get managedclusters --no-headers 2>/dev/null | wc -l)
          if [ "$MANAGED_COUNT" -gt "0" ]; then
            echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
            echo "â•‘  âŒ ERROR: YOU ARE ON THE HUB CLUSTER!                     â•‘"
            echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
            echo "â•‘  Performance tests MUST run on your SNO (target) cluster   â•‘"
            echo "â•‘  Running tests on the hub could affect management ops!     â•‘"
            echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""
            echo "Please switch to your SNO cluster first:"
            echo "  oc login https://api.<your-sno-cluster>:6443 -u kubeadmin -p <password>"
            exit 1
          fi
        fi
        
        echo "âœ“ Cluster check passed - proceeding with baseline test"
        echo "  Server: $(oc whoami --show-server)"
        echo ""
        
        if command -v kube-burner &> /dev/null; then
          if [ -f run-test.sh ]; then
            ./run-test.sh baseline
          else
            echo "Test script not found. Running manual baseline test..."
            cd ~/kube-burner-configs 2>/dev/null || mkdir -p ~/kube-burner-configs && cd ~/kube-burner-configs
            kube-burner init -c /projects/workshop/gitops/kube-burner-configs/baseline-config.yml --log-level=info
          fi
        else
          echo "kube-burner not found. Run 'Install kube-burner' first."
        fi
      group:
        kind: run

# Events for workspace lifecycle
events:
  postStart:
    - show-workshop-info
    - install-kube-burner
    - check-cluster-safety
